#!/usr/bin/env python
'''
    Python script that runs the job on the worker node and is started
    within the DailyPythonScripts directory
'''
import pickle
from optparse import OptionParser
from jobtypes import *
import shutil
import os
from tools.file_utilities import make_folder_if_not_exists

# from unfolding_pull_job import UnfoldingPullJob
parser = OptionParser(__doc__)
parser.add_option("-v", "--verbose", dest="verbose", action="store_true",
                  help="Show lots of logging")
(options, args) = parser.parse_args()
pickle_file_name = args[0]
job_id = args[1]
n_jobs = args[2]
print 'Job file:', pickle_file_name
print 'job ID:', job_id
print 'n_jobs:', n_jobs
job_id = int(job_id)
output_job_id = job_id
n_jobs = int(n_jobs)

pickle_file = open(pickle_file_name)
job = pickle.load(pickle_file)
# copy additional input files to where they should be
additional_input_files = job.additional_input_files
base_dir = os.environ['_CONDOR_JOB_IWD']
for f in additional_input_files:
    file_name = f.split('/')[-1]
    folder = f.replace(file_name, '')
    make_folder_if_not_exists(folder)
    shutil.copyfile(base_dir + '/' + file_name, f)

subjobs = job.split(n_jobs)
# pick the correct subjob
j = subjobs[job.filter_jobs[job_id]]
if job.filter_jobs:
    job_id = job.filter_jobs[job_id]
    j = subjobs[job_id]
    print 'new job ID:', job_id

j.run()

output_tar_file = j.tar_output(job_id)
output_file_name = output_tar_file.split('/')[-1]
shutil.copyfile(output_tar_file, base_dir + '/' + output_file_name)
