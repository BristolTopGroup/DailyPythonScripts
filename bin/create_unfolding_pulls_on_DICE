#!/usr/bin/env python
'''
    Submission script to DICE for src/unfolding_tests/create_unfolding_pull_data.py
'''
from __future__ import print_function
from optparse import OptionParser
from config import XSectionConfig
from condor import job
from condor.jobtypes.unfolding_pull_job import UnfoldingPullJob
import os
import sys


def main():
    parser = OptionParser(__doc__)
    parser.add_option("-c", "--com", dest="com", type=int,
                      help="Centre-of-mass energy to be used for submission")
    parser.add_option("-v", "--variables", dest="variables",
                      help="Variables to be analysed, separated by commas")
    parser.add_option("-i", "--input_file", dest="input_file",
                      help="Toy MC input file")
    parser.add_option("-f", "--filter_jobs", dest="filter_jobs",
                      help="Only submit jobs that match the IDs specified here. Multiple values separated by comma.",
                      default='')
    parser.add_option("-m", "--method", dest="method",
                      help="Unfolding method: RooUnfoldSvd (default), TSVDUnfold, RooUnfoldTUnfold, RooUnfoldInvert, RooUnfoldBinByBin, RooUnfoldBayes",
                      default='RooUnfoldSvd')
    (options, _) = parser.parse_args()

    # first the global variables
    centre_of_mass_energy = options.com
    config = XSectionConfig(centre_of_mass_energy)
    method = options.method
    n_toy_mc = n_toy_data = 300
    output_folder = 'data/pull_data/'
    offset_toy_mc = offset_toy_data = 0
    tau_value = -1
    k_value = -1

    variables = options.variables.split(',')
    filter_jobs = job.parse_filter_jobs(options.filter_jobs)
    input_file_name = options.input_file

    pull_jobs = []

    for variable in variables:
        # check if file exists
        if not os.path.exists(input_file_name):
            print('Input file {0} does not exist'.format(input_file_name))
            sys.exit(1)
        for channel in ['electron', 'muon']:
            if centre_of_mass_energy == 13:
                if channel == 'electron':
                    tau_value = config.tau_values_electron[variable]
                else:
                    tau_value = config.tau_values_muon[variable]
            else:
                if channel == 'electron':
                    k_value = config.k_values_electron[variable]
                else:
                    k_value = config.k_values_muon[variable]

            pull_job = UnfoldingPullJob(
                input_file_name=input_file_name,
                method=method,
                channel=channel,
                centre_of_mass=centre_of_mass_energy,
                variable=variable,
                n_toy_mc=n_toy_mc,
                n_toy_data=n_toy_data,
                output_folder=output_folder,
                offset_toy_mc=offset_toy_mc,
                offset_toy_data=offset_toy_data,
                k_value=k_value,
                tau_value=tau_value,
            )
            pull_jobs.append(pull_job)

    # Since we are analysing 300 x 300 = 90000 samples and one 10x10 sample
    # takes around 7 seconds it will take 1.75h in a single job.
    # For very fast (~1 min) processing we want at least 100 jobs.
    n_jobs_to_run = 100  # this is per pull_job
    n_jobs_to_split = 100
    if filter_jobs:
        n_jobs_to_run = len(filter_jobs)
    condor_job = job.Condor(n_jobs_to_run, n_jobs_to_split, request_memory=50)
    for j in pull_jobs:
        condor_job.add_job(j)
    condor_job.submit()
    print('All jobs submitted')


if __name__ == '__main__':
    main()
